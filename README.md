# üìö challange-1-book-search
Book Search √© um servi√ßo FastAPI que exp√µe endpoints REST sob /api/v1 para consultar cat√°logos de livros, efetuar buscas, 
filtrar por faixa de pre√ßo e obter estat√≠sticas agregadas sobre os t√≠tulos raspados do site p√∫blico Books to Scrape. 
O aplicativo √© montado pela classe AppBuilder, que registra os controladores de vers√£o, constr√≥i os casos de uso e injeta reposit√≥rios, 
clientes HTTP e infraestrutura de logging necess√°rios para executar o dom√≠nio orientado a casos de uso.

## üìë Sum√°rio

- [Vis√£o Geral](#vis√£o-geral)
- [Arquitetura](#arquitetura)
  - [Diagrama de arquitetura do projeto](#diagrama-de-arquitetura-do-projeto)
  - [Diagrama de sequ√™ncia das rotas e do script](#diagrama-de-sequ√™ncia-das-rotas-e-do-script)
  - [Diagrama C4 do projeto](#diagrama-c4-do-projeto)
- [Endpoints](#endpoints)
- [Pipeline de scraping e dados](#pipeline-de-scraping-e-dados)
- [Reproduzir o ambiente](#-reproduzir-o-ambiente)
- [Futuras melhorias](#-futuras-melhorias)

---

## üß≠Ô∏è Vis√£o Geral
- **Links de produ√ß√£o do projeto**: 
  - [Health Check](http://aws-cloud-challange-dev-alb-402052449.us-east-1.elb.amazonaws.com/api/v1/health)
  - [Swagger](http://aws-cloud-challange-dev-alb-402052449.us-east-1.elb.amazonaws.com/docs)
  - [Redoc](http://aws-cloud-challange-dev-alb-402052449.us-east-1.elb.amazonaws.com/redoc) <br><br>

- **Link v√≠deo de apresenta√ß√£o do projeto** <br><br>
  - [Link: Apresenta√ß√£o](https://1drv.ms/v/c/2f86df080e3673b3/EbGsD_4Ay-NBnxluDag35VsBIibzVvzaYFW1HdpFqVir7A?e=QausEk)
    - A visualiza√ß√£o direta pelo link est√° com uma qualidade inferior, favor realizar a download da apresenta√ß√£o atrav√©s:
    - ![download_apresentaacao.png](docs/imgs/download_apresentaacao.png)

- **Link acesso newrelic Instrumenta√ß√£o/Logs aplica√ß√£o em produ√ß√£o**:
  - [Link: NewRelic](https://1drv.ms/t/c/2f86df080e3673b3/Edk3x9aLlkVLjxonTRV53B0BMj18vbXuYnOZ3fpSBQZm2w?e=8Ub7Ag)<br><br>

- **Link acesso console aws**:
  - [Link: Aws-Console](https://1drv.ms/t/c/2f86df080e3673b3/ESBt-uIm4JJCryCEKT-flEsBSTGzqA8px7Y8uFkDgv5Q3g?e=LgcbqX)<br><br>
   
- API REST full-stack: Controllers FastAPI versionados em /api/v1 atendem consultas de sa√∫de, livros, categorias e estat√≠sticas 
  com respostas tipadas por esquemas Pydantic. <br><br>

- Dom√≠nio rico: Os livros s√£o representados por ScrapeBook (campos, identificadores, monetiza√ß√£o) e agrupados em ScrapeBooks, 
  que oferece buscas, filtros e estat√≠sticas de m√©dia de pre√ßo e distribui√ß√£o de avalia√ß√µes. <br><br>

- Casos de uso orquestrados: A UseCaseManagerImpl valida entradas, cria escopos de logging e encaminha exce√ß√µes/erros de 
  valida√ß√£o para presenters padronizados, resultando em respostas consistentes em JSON. <br><br>

- Cat√°logo persistido em CSV: O reposit√≥rio ScrapeBookRepositoryImpl carrega e grava src/data/books.csv, 
  mantendo cache em mem√≥ria para respostas mais r√°pidas. <br><br>

- Scraping ass√≠ncrono reutiliz√°vel: O caso de uso ScrapeBooksUseCaseImpl emprega httpx, BeautifulSoup e fake-useragent 
  para percorrer todas as p√°ginas, extrair atributos e persistir livros, podendo ser acionado tanto via script CLI quanto por pipelines de entrega. <br><br>

- Script pronto para automa√ß√£o: src/scripts/Main.py exp√µe uma corrotina de scraping execut√°vel com asyncio, 
  emitindo exce√ß√µes amig√°veis via presenter caso a coleta falhe. <br><br>

---

## üèóÔ∏è Arquitetura
### Composi√ß√£o e orquestra√ß√£o
AppBuilder encapsula a composi√ß√£o de depend√™ncias (logger contextual, f√°brica de clientes HTTP e reposit√≥rio) e registra 
todos os casos de uso no UseCaseManagerImpl, que trata valida√ß√µes, escopos de log e propaga√ß√£o de erros antes de invocar 
cada caso de uso.

### Camada de dom√≠nio
Os modelos ScrapeBook e ScrapeBooks formam o n√∫cleo de dom√≠nio: cada livro possui VOs fortes (Rating, Money, Upc) e um 
identificador incremental thread-safe, enquanto a cole√ß√£o controla categorias, filtros, ranking por avalia√ß√£o, estat√≠sticas 
de pre√ßo e disponibilidade.

### Persist√™ncia
ScrapeBookRepositoryImpl l√™ e grava o cat√°logo em CSV, com cache global _CACHE para evitar reprocessamentos. 
Na aus√™ncia do arquivo, o reposit√≥rio retorna uma cole√ß√£o vazia pronta para ser abastecida pelo scraper.

### Web scraping
ScrapeBooksUseCaseImpl percorre as p√°ginas de cat√°logo, normaliza ratings para inteiros, extrai metadados e cria objetos
de dom√≠nio. Falhas ao carregar p√°ginas ou links espec√≠ficos s√£o reportadas ao presenter, evitando persist√™ncia parcial.

### Observabilidade
A configura√ß√£o de logs √© centralizada em SetupAppLogger, aplicando filtros para suprimir health checks, enquanto 
AppLoggerImpl mant√©m escopos hier√°rquicos com metadados adicionais para cada execu√ß√£o de caso de uso.

- ### Diagrama de arquitetura do projeto
  diagrama: `docs/diagrams/High-Level Architecture Diagram.mermaid`
  ![High-Level Architecture Diagram](docs/diagrams/High-Level%20Architecture%20Diagram.png)

- ### Diagrama de sequ√™ncia das rotas e do script
  diagrama: `docs/diagrams/Sequencia Routes and Script Diagram.mermaid`
  ![Sequencia Routes and Script Diagram](docs/diagrams/Sequencia%20Routes%20and%20Script%20Diagram.png)

  A sequ√™ncia evidencia o fluxo padr√£o dos controladores (delega√ß√£o ao caso de uso, reuso do cat√°logo em cache) e o 
  pipeline de scraping que percorre o site, atualiza o CSV e reporta falhas via presenter espec√≠fico

- ### Diagrama C4 do projeto
  diagrama: `docs/diagrams/Diagram C4 Context.mermaid`
  ![Diagram C4 Context.png](docs/diagrams/Diagram%20C4%20Context.png)
  
  #### Notas de contexto
  * A aplica√ß√£o FastAPI √© constru√≠da por `AppBuilder`, que instancia os controladores HTTP e exp√µe o objeto `app` em `src/api/Main.py`. <br>
  * A coleta de dados depende do site externo Books to Scrape, consumido pela use case `ScrapeBooksUseCaseImpl` via HTTPX.<br><br> 

  diagrama: `docs/diagrams/Diagram C4 Containers.mermaid`
  ![Diagram C4 Containers.png](docs/diagrams/Diagram%20C4%20Context.png) 

  diagrama: `docs/diagrams/Diagram C4 Components FastApi Backend.mermaid`
  ![Diagram C4 Components FastApi Backend.png](docs/diagrams/Diagram%20C4%20Components%20FastApi%20Backend.png)

  diagrama: `docs/diagrams/Diagram C4 Components Scraping Worker.mermaid`
  ![img.png](docs/diagrams/Diagram%20C4%20Components%20Scraping%20Worker.png)

---

## Endpoints
Todas as rotas REST ficam sob o prefixo /api/v1 (configurado no roteador base).

| M√©todo | Rota | Descri√ß√£o | Par√¢metros principais | Resposta |
| --- | --- | --- | --- | --- |
| GET | `/api/v1/health` | Health-check simples. | ‚Äî | `{"result": true}` ‚Äì `HealthCheckOutput`. |
| GET | `/api/v1/books` | Lista todos os livros carregados. | ‚Äî | Lista de `BookOutput`. |
| GET | `/api/v1/books/search` | Busca por t√≠tulo e/ou categoria (case-insensitive). | Query `title` e/ou `category`. | Lista de `BookOutput`. Retorna todos se ambos vazios. |
| GET | `/api/v1/books/top-rated` | Top 10 livros com maior nota. | ‚Äî | Lista de `BookOutput` ordenada por rating. |
| GET | `/api/v1/books/price-range` | Filtra livros por faixa de pre√ßo. | Query obrigat√≥ria `min_price` e `max_price` (Decimal). | Lista de `BookOutput` crescente por pre√ßo. Valida que `min_price ‚â§ max_price`. |
| GET | `/api/v1/books/{book_id}` | Retorna detalhes de um livro. | Path `book_id` (inteiro >= 0). | `BookOutput` ou `{}` (404). |
| GET | `/api/v1/categories` | Lista todas as categorias conhecidas. | ‚Äî | Lista de strings (categoria). |
| GET | `/api/v1/stats/overview` | Estat√≠sticas gerais (contagem, ticket m√©dio, distribui√ß√£o de rating). | ‚Äî | Objeto `BookStatsOutput`. |
| GET | `/api/v1/stats/categories` | Estat√≠sticas por categoria. | ‚Äî | Dict `{categoria: BookStatsOutput}`. |

---

## Pipeline de scraping e dados
O script `poetry run python -m src.scripts.Main` aciona o caso de uso de scraping via `AppBuilder`, que instancia o client HTTP (`httpx`), coleta todas as p√°ginas do cat√°logo, monta objetos `ScrapeBook` e, ao final, salva o resultado no CSV cacheado dentro de `src/data/books.csv`. O reposit√≥rio reaproveita um cache em mem√≥ria para servir leituras subsequentes com baixo custo.

###  Como reproduzir localmente o scraping
1. **Requisitos** ‚Äì Python 3.12+ e Poetry s√£o necess√°rios, conforme declarado em `pyproject.toml` (inclui depend√™ncias FastAPI, BeautifulSoup, httpx, fake-useragent, etc.).
2. **Instala√ß√£o** ‚Äì Execute `poetry install` para resolver depend√™ncias e o grupo de desenvolvimento definido no arquivo de projeto.
3. **Popular os dados** ‚Äì Rode `poetry run python -m src.scripts.Main` para baixar e persistir o cat√°logo no CSV local antes de subir a API (opcional, caso j√° exista `books.csv`).
4. **Subir a API** ‚Äì Inicie o servidor com `poetry run uvicorn src.api.Main:app --reload`. O aplicativo exp√µe OpenAPI em `/openapi.json`, Swagger UI em `/docs` e Redoc em `/redoc`.

---

## üîÅ Reproduzir o ambiente
Este projeto foi estruturado para rodar localmente e em um ambiente produtivo (nuvem) por meio de um pipeline automatizado 
orquestrado pelo script.sh. A l√≥gica √© tradicional ‚Äî build, testes, empacotamento, deploy ‚Äî mas com um toque 
moderno: um √∫nico ponto de entrada com alvos expl√≠citos para CI/CD.

>   Conven√ß√£o: todos os comandos abaixo assumem Linux/WSL/macOS. <br>
    No Windows puro, rode via WSL. <br>

### üñ•Ô∏è Execu√ß√£o local
- **Pr√©-requisitos**: 
  - Python 3.12+ 
  - Poetry.
- **Instala√ß√£o de depend√™ncias**:
  ```bash
  poetry install
  ```
- **Comandos principais do `script.sh`**:
  - `./script.sh ci:build` ‚Äì executa `poe fmt`, `poe lint` e `poe typecheck` em sequ√™ncia.
  - `./script.sh ci:audit` ‚Äì roda a auditoria configurada em `poe audit`.
  - `./script.sh ci:test:unit` ‚Äì dispara os testes unit√°rios (`poe test_unit`).
  - `./script.sh ci:test:integration` ‚Äì executa os testes de integra√ß√£o (`poe test_integration`).
  - `./script.sh ci:test:e2e` ‚Äì roda os testes end-to-end (`poe test_e2e`).
  - `./script.sh ci:all` ‚Äì limpa o ambiente, sincroniza depend√™ncias e executa audit, build e testes (unit e integration) em sequ√™ncia.
- **Popular o cat√°logo local**:
  ```bash
  poetry run python -m src.scripts.Main
  ```
- **Executar a API**:
  ```bash
  poetry run uvicorn src.api.Main:app --reload
  ```

### ‚òÅÔ∏è Execu√ß√£o em ambiente ‚Äúprodutivo‚Äù
- **Pr√©-requisitos**: 
  - Python 3.12+
  - Poetry
  - Docker
  - Terraform
  - AWS CLI
  - New Relic CLI/Agent configur√°vel. <br><br>
  
- **Configura√ß√£o de segredos**:
  1. Criar o arquivo `infra/terraform/aws/.aws_credentials` com as credenciais do usu√°rio (`aws_access_key_id=...` e `aws_secret_access_key=...`).
  2. Criar o arquivo `newrelic.ini` na raiz do projeto (pode ser baseado em `sample.newrelic.ini`) com as chaves da conta New Relic. <br><br>
  
- **Provisionar infraestrutura** (VPC, ECR, ECS, Tasks etc.) utilizando o `script.sh`:
  ```bash
  ./script.sh infra:init
  ./script.sh infra:plan
  ./script.sh infra:apply
  ```
- **Pipeline de qualidade e build**:
  ```bash
  ./script.sh ci:audit
  ./script.sh ci:build
  ./script.sh ci:test:unit
  ./script.sh ci:test:integration
  ./script.sh ci:test:e2e
  ```
- **Ciclo de CD**:
  1. `./script.sh cd:build execute_scrape` ‚Äì realiza o build da imagem Docker e executa o scraping antes do empacotamento.
  2. `./script.sh cd:push` ‚Äì realiza login no ECR (criando o reposit√≥rio se necess√°rio) e publica a imagem com a tag calculada.
  3. `./script.sh cd:deploy` ‚Äì atualiza o servi√ßo ECS apontando para a nova Task Definition e aguarda a estabiliza√ß√£o.
  4. (Opcional) `./script.sh utils:logs_ecs_events` para inspecionar os √∫ltimos eventos do servi√ßo.

Com essa rotina, o projeto pode ser constru√≠do, testado e publicado em ambiente produtivo utilizando os mesmos artefatos 
gerados localmente. <br>

**Verifica√ß√µes p√≥s-deploy**: <br>
- Health: acesse o endpoint /api/v1/health do ALB p√∫blico.
- Observabilidade:
  - Verifique o servi√ßo no New Relic APM com o nome configurado (NEW_RELIC_APP_NAME).
  - Consulte logs e m√©tricas de container/APP (NR Logs e NR Metrics/Infra).

---

## üîÆ Futuras melhorias
- **Autentica√ß√£o e autoriza√ß√£o**: implementar fluxo de login com emiss√£o de tokens JWT para proteger rotas sens√≠veis, 
  permitindo pap√©is distintos (admin, leitor) e expira√ß√£o/refresh automatizados.
- **Endpoints de machine learning**: disponibilizar as rotas de ML previstas no escopo original, integrando modelos de 
  recomenda√ß√£o ou classifica√ß√£o para enriquecer a experi√™ncia de busca.
- **Pipeline de CI/CD gerenciado**: migrar o `script.sh` para uma ferramenta como GitHub Actions ou GitLab CI, 
  garantindo execu√ß√£o autom√°tica dos jobs de qualidade, build e deploy a cada push em branches principais.
- **DNS amig√°vel**: provisionar um dom√≠nio gerenciado via Route53 apontando para o Load Balancer, com certificados TLS 
  v√°lidos (ACM) e redirecionamento HTTPS for√ßado.
- **Observabilidade e custo**: configurar alertas proativos (CloudWatch, New Relic) para erro/lat√™ncia e revisar pol√≠ticas 
  de autoscaling para evitar sobrecusto e melhorar resili√™ncia.

---